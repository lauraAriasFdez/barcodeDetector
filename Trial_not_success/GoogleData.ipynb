{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GoogleData.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "TiqW1Fb6e6i-"
      ],
      "authorship_tag": "ABX9TyNANG/WHaZNCrOL7xwS9769",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lauraAriasFdez/barcodeDetector/blob/main/GoogleData.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 - Fityone download\n",
        "Errors not detection but usign segmentation"
      ],
      "metadata": {
        "id": "TiqW1Fb6e6i-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYLHrWE6ae35"
      },
      "outputs": [],
      "source": [
        "!sudo apt install -y ffmpeg\n",
        "!pip install fiftyone\n",
        "\n",
        "\n",
        "# handle error of cv2 headless when importing fiftyone\n",
        "!pip uninstall opencv-python-headless==4.5.5.62\n",
        "!pip install opencv-python-headless==4.5.2.52\n",
        "\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = foz.load_zoo_dataset(\n",
        "              \"open-images-v6\",\n",
        "              split=\"validation\",\n",
        "              label_types=[\"detections\", \"segmentations\"],\n",
        "              classes=[\"Cat\", \"Dog\"],\n",
        "              max_samples=100,\n",
        "          )\n",
        "\n",
        "path_of_img = \"/root/fiftyone/open-images-v6/validation/data/\"\n",
        "img_detections = \"/root/fiftyone/open-images-v6/validation/labels/detections.csv\"\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2A5sfItyaidV",
        "outputId": "968d6768-7b2a-4103-a84c-6c2e65f8b824"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'validation' to '/root/fiftyone/open-images-v6/validation' if necessary\n",
            "Downloading 'https://storage.googleapis.com/openimages/2018_04/validation/validation-images-with-rotation.csv' to '/root/fiftyone/open-images-v6/validation/metadata/image_ids.csv'\n",
            "Downloading 'https://storage.googleapis.com/openimages/v5/class-descriptions-boxable.csv' to '/root/fiftyone/open-images-v6/validation/metadata/classes.csv'\n",
            "Downloading 'https://storage.googleapis.com/openimages/v5/classes-segmentation.txt' to '/root/fiftyone/open-images-v6/validation/metadata/segmentation_classes.csv'\n",
            "Downloading 'https://storage.googleapis.com/openimages/2018_04/bbox_labels_600_hierarchy.json' to '/tmp/tmp9onuoye_/metadata/hierarchy.json'\n",
            "Downloading 'https://storage.googleapis.com/openimages/v5/validation-annotations-bbox.csv' to '/root/fiftyone/open-images-v6/validation/labels/detections.csv'\n",
            "Downloading 'https://storage.googleapis.com/openimages/v5/validation-annotations-object-segmentation.csv' to '/root/fiftyone/open-images-v6/validation/labels/segmentations.csv'\n",
            "Downloading 100 images\n",
            " 100% |███████████████████| 100/100 [10.9s elapsed, 0s remaining, 9.9 files/s]      \n",
            "Dataset info written to '/root/fiftyone/open-images-v6/info.json'\n",
            "Loading 'open-images-v6' split 'validation'\n",
            " 100% |█████████████████| 100/100 [1.7s elapsed, 0s remaining, 59.5 samples/s]         \n",
            "Dataset 'open-images-v6-validation-100' created\n",
            "Name:        open-images-v6-validation-100\n",
            "Media type:  image\n",
            "Num samples: 100\n",
            "Persistent:  False\n",
            "Tags:        ['validation']\n",
            "Sample fields:\n",
            "    id:             fiftyone.core.fields.ObjectIdField\n",
            "    filepath:       fiftyone.core.fields.StringField\n",
            "    tags:           fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
            "    metadata:       fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.Metadata)\n",
            "    detections:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    segmentations:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
            "    open_images_id: fiftyone.core.fields.StringField\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O8MrtkXZcb2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imShow(path):\n",
        "  import cv2\n",
        "  import matplotlib.pyplot as plt\n",
        "  %matplotlib inline\n",
        "\n",
        "  image = cv2.imread(path)\n",
        "  height, width = image.shape[:2]\n",
        "  resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "  fig = plt.gcf()\n",
        "  fig.set_size_inches(18, 10)\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "2KB2P0oGcXkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the objects in the `predictions` field with respect to the\n",
        "# objects in the `ground_truth` field\n",
        "results = dataset.evaluate_detections(\n",
        "    \"predictions\",\n",
        "    gt_field=\"ground_truth\",\n",
        "    method=\"open-images\",\n",
        "    eval_key=\"eval\",\n",
        ")"
      ],
      "metadata": {
        "id": "WutjeW_EblLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "GVNxpzeafMRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 - Freiburg groceries dataset Download\n",
        "\n",
        "having errors with the dependencies of caffe module\n",
        "\n",
        "Need to manually Split data into training and testing !!!!  (too much work)\n",
        "\n",
        "https://github.com/PhilJd/freiburg_groceries_dataset\n",
        "\n"
      ],
      "metadata": {
        "id": "Gp9PxIi5k56S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/PhilJd/freiburg_groceries_dataset.git\n",
        "%cd freiburg_groceries_dataset/src\n",
        "!python download_dataset.py"
      ],
      "metadata": {
        "id": "FZWwgiYAlCnu",
        "outputId": "d9d9275f-d324-47dc-c77a-9785aa97f815",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'freiburg_groceries_dataset'...\n",
            "remote: Enumerating objects: 123, done.\u001b[K\n",
            "remote: Total 123 (delta 0), reused 0 (delta 0), pack-reused 123\u001b[K\n",
            "Receiving objects: 100% (123/123), 6.54 MiB | 16.99 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n",
            "/content/freiburg_groceries_dataset/src\n",
            "Downloading dataset.\n",
            "Traceback (most recent call last):\n",
            "  File \"download_dataset.py\", line 10, in <module>\n",
            "    urlretrieve(dataset_url, \"../freiburg_groceries_dataset.tar.gz\")\n",
            "  File \"/usr/lib/python3.7/urllib/request.py\", line 276, in urlretrieve\n",
            "    block = fp.read(bs)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 465, in read\n",
            "    n = self.readinto(b)\n",
            "  File \"/usr/lib/python3.7/http/client.py\", line 509, in readinto\n",
            "    n = self.fp.readinto(b)\n",
            "  File \"/usr/lib/python3.7/socket.py\", line 589, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#libraries are required: caffe, cuda, boost, python3, numpy. \n",
        "# !pip install cuda  - gpu runtime in edits settings \n",
        "!pip install boost\n",
        "!pip install numpy\n",
        "\n",
        "\n",
        "# install caffe\n",
        "#!pip install caffe\n",
        "#!apt install -y caffe-cuda\n",
        "!apt install -y caffe-cuda"
      ],
      "metadata": {
        "id": "qqIRO1CGlQj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "source of code bellow caffe2\n",
        "https://colab.research.google.com/drive/1JPNinBHwXlkOAFje1ZMKdxbgIIRHcsN6#scrollTo=sYOtPwuovRpW\n",
        "\"\"\"\n",
        "\n",
        "#!wget https://anaconda.org/pytorch/pytorch-nightly/1.0.0.dev20181206/download/linux-64/pytorch-nightly-1.0.0.dev20181206-py2.7_cuda9.2.148_cudnn7.4.1_0.tar.bz2\n",
        "#!tar xvjf pytorch-nightly-1.0.0.dev20181206-py2.7_cuda9.2.148_cudnn7.4.1_0.tar.bz2\n",
        "#!cp -r lib/python2.7/site-packages/* /usr/local/lib/python2.7/dist-packages/\n",
        "\n",
        "\n",
        "#!python -c 'from caffe2.python import core' 2>/dev/null && echo \"Success\" || echo \"Failure\""
      ],
      "metadata": {
        "id": "EV-bs5KQlQr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls\n",
        "#!python install.py\n",
        "\n",
        "\n",
        "# leave ferg dataset directory\n",
        "%cd ../..\n",
        "%ls"
      ],
      "metadata": {
        "id": "EscXX1mQlS2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 - OIDv4 Download "
      ],
      "metadata": {
        "id": "DM-Hr7RLfHt9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/EscVM/OIDv4_ToolKit.git\n",
        "%cd OIDv4_ToolKit/\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "3tx4iGAFfOWK",
        "outputId": "5de76ee4-6b3c-44ac-b3ab-89760caa6ab0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'OIDv4_ToolKit'...\n",
            "remote: Enumerating objects: 422, done.\u001b[K\n",
            "remote: Total 422 (delta 0), reused 0 (delta 0), pack-reused 422\u001b[K\n",
            "Receiving objects: 100% (422/422), 34.08 MiB | 30.21 MiB/s, done.\n",
            "Resolving deltas: 100% (146/146), done.\n",
            "/content/freiburg_groceries_dataset/src/OIDv4_ToolKit\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (1.19.5)\n",
            "Collecting awscli\n",
            "  Downloading awscli-1.22.51-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.24.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (4.62.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (4.1.2.30)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->-r requirements.txt (line 1)) (1.15.0)\n",
            "Collecting docutils<0.16,>=0.10\n",
            "  Downloading docutils-0.15.2-py3-none-any.whl (547 kB)\n",
            "\u001b[K     |████████████████████████████████| 547 kB 45.4 MB/s \n",
            "\u001b[?25hCollecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.1-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting colorama<0.4.4,>=0.2.5\n",
            "  Downloading colorama-0.4.3-py2.py3-none-any.whl (15 kB)\n",
            "Collecting botocore==1.23.51\n",
            "  Downloading botocore-1.23.51-py3-none-any.whl (8.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5 MB 36.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML<5.5,>=3.10 in /usr/local/lib/python3.7/dist-packages (from awscli->-r requirements.txt (line 3)) (3.13)\n",
            "Collecting rsa<4.8,>=3.1.2\n",
            "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
            "Collecting urllib3\n",
            "  Downloading urllib3-1.26.8-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 32.9 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<4.8,>=3.1.2->awscli->-r requirements.txt (line 3)) (0.4.8)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, rsa, docutils, colorama, awscli\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: rsa\n",
            "    Found existing installation: rsa 4.8\n",
            "    Uninstalling rsa-4.8:\n",
            "      Successfully uninstalled rsa-4.8\n",
            "  Attempting uninstall: docutils\n",
            "    Found existing installation: docutils 0.17.1\n",
            "    Uninstalling docutils-0.17.1:\n",
            "      Successfully uninstalled docutils-0.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.8 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed awscli-1.22.51 botocore-1.23.51 colorama-0.4.3 docutils-0.15.2 jmespath-0.10.0 rsa-4.7.2 s3transfer-0.5.1 urllib3-1.26.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%ls\n",
        "\n",
        "# limit for each class is 1000 as recommended by google cloud \n",
        "#https://cloud.google.com/vision/automl/object-detection/docs/prepare   \n",
        "!python3 main.py downloader --classes Apple Orange Coffee Tea --type_csv train --limit 1000 --multiclasses 1 \n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlH6VJunfyhg",
        "outputId": "676ea5f2-b42b-4ad2-ba33-6c818946e783"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classes.txt  LICENSE  \u001b[0m\u001b[01;34mmodules\u001b[0m/        README.md\n",
            "\u001b[01;34mimages\u001b[0m/      main.py  \u001b[01;34mOIDv4_ToolKit\u001b[0m/  requirements.txt\n",
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading ['Apple', 'Orange', 'Coffee', 'Tea'] together.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the class-descriptions-boxable.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0my\n",
            "...145%, 0 MB, 55690 KB/s, 0 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File class-descriptions-boxable.csv downloaded into OID/csv_folder/class-descriptions-boxable.csv.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the train-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0mY\n",
            "...100%, 1138 MB, 55659 KB/s, 20 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File train-annotations-bbox.csv downloaded into OID/csv_folder/train-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mApple\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 1078 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 1000 images.\u001b[0m\n",
            "    [INFO] | Download of 1000 images in train.\u001b[0m\n",
            "100% 1000/1000 [08:56<00:00,  1.86it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Apple of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "\n",
            "\u001b[95mOrange\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 900 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 1000 images.\u001b[0m\n",
            "    [INFO] | Download of 861 images in train.\u001b[0m\n",
            "100% 861/861 [07:19<00:00,  1.96it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Orange of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "\n",
            "\u001b[95mCoffee\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 1858 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 1000 images.\u001b[0m\n",
            "    [INFO] | Download of 999 images in train.\u001b[0m\n",
            "100% 999/999 [08:19<00:00,  2.00it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Coffee of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "\n",
            "\u001b[95mTea\u001b[0m\n",
            "    [INFO] | Downloading train images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 1068 online images for train.\u001b[0m\n",
            "    [INFO] | Limiting to 1000 images.\u001b[0m\n",
            "    [INFO] | Download of 695 images in train.\u001b[0m\n",
            "100% 695/695 [05:40<00:00,  2.04it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Tea of train.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 main.py downloader --classes Apple Orange Coffee Tea --type_csv validation --limit 100 --multiclasses 1 \n"
      ],
      "metadata": {
        "id": "w9Q6t-Pmn4h5",
        "outputId": "9826037c-dc15-45a1-b18b-41545e89bb7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[92m\n",
            "\t\t   ___   _____  ______            _    _    \n",
            "\t\t .'   `.|_   _||_   _ `.         | |  | |   \n",
            "\t\t/  .-.  \\ | |    | | `. \\ _   __ | |__| |_  \n",
            "\t\t| |   | | | |    | |  | |[ \\ [  ]|____   _| \n",
            "\t\t\\  `-'  /_| |_  _| |_.' / \\ \\/ /     _| |_  \n",
            "\t\t `.___.'|_____||______.'   \\__/     |_____|\n",
            "\t\u001b[0m\n",
            "\u001b[92m\n",
            "             _____                    _                 _             \n",
            "            (____ \\                  | |               | |            \n",
            "             _   \\ \\ ___  _ _ _ ____ | | ___   ____  _ | | ____  ____ \n",
            "            | |   | / _ \\| | | |  _ \\| |/ _ \\ / _  |/ || |/ _  )/ ___)\n",
            "            | |__/ / |_| | | | | | | | | |_| ( ( | ( (_| ( (/ /| |    \n",
            "            |_____/ \\___/ \\____|_| |_|_|\\___/ \\_||_|\\____|\\____)_|    \n",
            "                                                          \n",
            "        \u001b[0m\n",
            "    [INFO] | Downloading ['Apple', 'Orange', 'Coffee', 'Tea'] together.\u001b[0m\n",
            "\u001b[91m   [ERROR] | Missing the validation-annotations-bbox.csv file.\u001b[0m\n",
            "\u001b[94m[DOWNLOAD] | Do you want to download the missing file? [Y/n] \u001b[0my\n",
            "...100%, 16 MB, 63084 KB/s, 0 seconds passed\n",
            "\u001b[94m[DOWNLOAD] | File validation-annotations-bbox.csv downloaded into OID/csv_folder/validation-annotations-bbox.csv.\u001b[0m\n",
            "\n",
            "\u001b[95mApple\u001b[0m\n",
            "    [INFO] | Downloading validation images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 46 online images for validation.\u001b[0m\n",
            "    [INFO] | Limiting to 100 images.\u001b[0m\n",
            "    [INFO] | Download of 46 images in validation.\u001b[0m\n",
            "100% 46/46 [00:33<00:00,  1.37it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Apple of validation.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "\n",
            "\u001b[95mOrange\u001b[0m\n",
            "    [INFO] | Downloading validation images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 61 online images for validation.\u001b[0m\n",
            "    [INFO] | Limiting to 100 images.\u001b[0m\n",
            "    [INFO] | Download of 61 images in validation.\u001b[0m\n",
            "100% 61/61 [00:38<00:00,  1.58it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Orange of validation.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "\n",
            "\u001b[95mCoffee\u001b[0m\n",
            "    [INFO] | Downloading validation images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 109 online images for validation.\u001b[0m\n",
            "    [INFO] | Limiting to 100 images.\u001b[0m\n",
            "    [INFO] | Download of 100 images in validation.\u001b[0m\n",
            "100% 100/100 [01:02<00:00,  1.60it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Coffee of validation.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n",
            "\n",
            "\u001b[95mTea\u001b[0m\n",
            "    [INFO] | Downloading validation images.\u001b[0m\n",
            "    [INFO] | [INFO] Found 44 online images for validation.\u001b[0m\n",
            "    [INFO] | Limiting to 100 images.\u001b[0m\n",
            "    [INFO] | Download of 13 images in validation.\u001b[0m\n",
            "100% 13/13 [00:11<00:00,  1.17it/s]\n",
            "    [INFO] | Done!\u001b[0m\n",
            "    [INFO] | Creating labels for Tea of validation.\u001b[0m\n",
            "    [INFO] | Labels creation completed.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert data to format yolov4 accepts "
      ],
      "metadata": {
        "id": "cjHMekoipu8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. After downloading I need to convert into proper yolov4 format\n",
        "  - If you open the train and validation folder, you will see that there is a “Labels” folder inside them as well. It contains bounding boxes for the object in the images we downloaded. But we can not use them since these are annotations as one object type per image. It means that if an image contains “number plates” and “cars”, the annotations will have bounding boxes for only cars or only number plates. But we need annotations for every object in the image. This can be better understood by the following diagram.\n",
        "\n",
        "- Yolo is trained better when it sees lots of information in one image, so we need to change it into the new format. For this remove the Labels folder from the “train” and “validation” folders.\n",
        "\n",
        "- To prepare the dataset, we will use LabelImg (Installation procedure explained in the Github repo). It is a free open source Image annotator that we can use to create annotations in YOLOv4 format. \n",
        "\n",
        "https://techylem.com/yolov4-guide-with-code/\n",
        "\n",
        "2. Upload zip file with img to google drive in order to train   obj.zip test.zip\n",
        "\n",
        "\n",
        "TRAINING\n",
        "1. Confugure parameters of training by downloading cfg file  and CHANGE IT\n",
        "\n"
      ],
      "metadata": {
        "id": "kx06wFChjrNK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "jY2_4QDEodfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Apple \n",
        "Bagel\n",
        "Banana\n",
        "Bell pepper\n",
        "Bread\n",
        "Broccoli\n",
        "Burrito\n",
        "Cabbage\n",
        "Cake\n",
        "Candy\n",
        "Carrot \n",
        "Cheese\n",
        "Cocconut\n",
        "Coffee\n",
        "Cokie\n",
        "Cooking spray\n",
        "Cream\n",
        "Croissant\n",
        "Cucumber\n",
        "Waffle\n",
        "Tea\n",
        "Salad \n",
        "Sushi\n",
        "Squash (Plant)\n",
        "Sandwich\n",
        "Soap dispenser \n",
        "Strawberry \n",
        "Toilet Paper\n",
        "Tomatole\n",
        "Vegetabe \n",
        "Watermelon \n",
        "Wine\n",
        "Winter melon\n",
        "Zucchini\n",
        "Fish \n",
        "Shrimp\n",
        "Seafood\n",
        "Pumpkin\n",
        "Pretzel \n",
        "Potato\n",
        "Popcorn\n",
        "Pizza\n",
        "Pineaplle \n",
        "Pre\n",
        "Baked goods?\n",
        "Pasta\n",
        "Perfume\n",
        "Paper towel\n",
        "Toilet paper\n",
        "Pastry\n",
        "Pancake \n",
        "orange\n",
        "Mango \n",
        "Lobster  \n",
        "Milk\n",
        "Lemon\n",
        "Kitchen utensil\n",
        "Ice cream\n",
        "Hamburger\n",
        "Guacamole\n",
        "Fruit\n",
        "Grape\n",
        "Flower\n",
        "Juice\n",
        "Egg (Food)\n",
        "French fries\n",
        "Doughnut\n",
        "\n",
        "\n",
        "Fruit Pastry \"Egg (Food)\" Pasta Candy Coffee Tea Vegetable \"Toilet Paper\" Milk Fruit Flower Popcorn Fish Bread \"Ice cream\"\n",
        "Juice Sandwich Sushi Candy Cheese Cookie\n",
        "\"Cooking spray\" Salad\n",
        "\n",
        "\n",
        "Error when downloading Egg (Food) ???????"
      ],
      "metadata": {
        "id": "ukIq-zqyGa_J"
      }
    }
  ]
}